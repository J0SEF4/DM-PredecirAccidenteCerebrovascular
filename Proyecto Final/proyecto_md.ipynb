{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pontificia Universidad Católica de Chile <br>\n",
    "Departamento de Ciencia de la Computación <br>\n",
    "IIC2433 - Minería de Datos\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <h2> Proyecto Mineria de Datos</h2>\n",
    "    <h1> Predecir un accidente cerebrovascular </h1>\n",
    "    <p>\n",
    "        Profesor Marcelo Mendoza<br>\n",
    "        Primer Semestre 2023<br>    \n",
    "        Fecha de entrega: Martes 13 de Junio\n",
    "    </p>\n",
    "    <p>Integrantes: Lucas Aguilera, Claudio Bórquez, Josefa Fernández\n",
    "    </p>\n",
    "    <br>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan las librerias ausar en este proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Analisis de Datos, preparación y selección de caracteristicas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Carga de datos\n",
    "- Se descarga el conjunto de datos del enlace proporcionado.\n",
    "\n",
    "Durante este proyecto se usan datos clínicos, centrados en accidentes cerebrovasculares, obtendios de Kaggle:\n",
    "\n",
    "https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe = pd.read_csv(\"../data/healthcare-dataset-stroke-data.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Exploración de datos\n",
    "- Se exploran los datos para comprender la estrucutura, caracteristicas y posibles problemas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56669</td>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53882</td>\n",
       "      <td>Male</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>70.09</td>\n",
       "      <td>27.4</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10434</td>\n",
       "      <td>Female</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>94.39</td>\n",
       "      <td>22.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27419</td>\n",
       "      <td>Female</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>76.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60491</td>\n",
       "      <td>Female</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>58.57</td>\n",
       "      <td>24.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "5  56669    Male  81.0             0              0          Yes   \n",
       "6  53882    Male  74.0             1              1          Yes   \n",
       "7  10434  Female  69.0             0              0           No   \n",
       "8  27419  Female  59.0             0              0          Yes   \n",
       "9  60491  Female  78.0             0              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "5        Private          Urban             186.21  29.0  formerly smoked   \n",
       "6        Private          Rural              70.09  27.4     never smoked   \n",
       "7        Private          Urban              94.39  22.8     never smoked   \n",
       "8        Private          Rural              76.15   NaN          Unknown   \n",
       "9        Private          Urban              58.57  24.2          Unknown   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los datos contienen 5110 observaciones con 12 atributos.\n",
    "- Se observa valores nulos en la columna bmi\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset se utiliza para predecir si es probable que un paciente sufra un accidente cerebrovascular en función de los parámetros de entrada como el sexo, la edad, diversas enfermedades y el tabaquismo. Cada fila de los datos proporciona información relevante sobre el paciente.\n",
    "\n",
    "El dataset, que se usará  para construir un modelo para predecir. Los atributos que contiene son:\n",
    "- id: identificador unico\n",
    "- gender: \"Male\", \"Female\" or \"Other\" (\"Masculino\", \"Femenino\" u \"Otro\")\n",
    "- age: edad del paciente\n",
    "- hypertension: 0 si el paciente no tiene hipertension, 1 si el paciente tiene hipertension\n",
    "- heart_disease: 0 si el paciente no tiene ninguna enfermedad al corazón, 1 si el paciente tiene alguna enfermedad al corazón \n",
    "- ever_married: \"No\" or \"Yes\" (\"No\" o \"Si\")\n",
    "- work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\" (\"niños\", \"Govt_jov\", \"nunca_ha_trabajo\", \"Privado\" o \"Independiente\")\n",
    "- Residence_type: \"Rural\" or \"Urban\" (\"Rural\" o \"Urbano\")\n",
    "- avg_glucose_level: el promedio del nivel de glucosa en la sangre\n",
    "- bmi: índice de masa corporal\n",
    "- smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"* (\"anteriormente fumó\", \"nunca fumó\", \"fuma\"o \"Desconocido\"*)\n",
    "- stroke: 1 si el paciente tuvo un accidente cerebrovascular o 0 si no\n",
    "\n",
    "*Nota: \"Desconocido\" en smoking_status significa que la información no está disponible para este paciente\n",
    "\n",
    "Toda esta informacion fue sacada de kaggle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Preprocesamiento\n",
    "- Se realiza una limpieza de datos para manejar valores faltantes, duplicados u otros errores.\n",
    "- Realizar una transformación de datos si es necesario, como codificación de variables categóricas.\n",
    "\n",
    "Se preprocesan los datos, por lo que consideraros si es necesario hacer entre otras, las siguientes cosas:\n",
    "- Remover columnas\n",
    "- Normalizar variables\n",
    "- Manejo de valores nulos\n",
    "\n",
    "Para manejar los datos categoricos tienes que usar One Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe.head(5) #verifico los 1eros 5 registros del dframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Veo valores nulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "ever_married           0\n",
       "work_type              0\n",
       "Residence_type         0\n",
       "avg_glucose_level      0\n",
       "bmi                  201\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remover columnas\n",
    "Saco columnas que no aportan informacion relevante para el modelo  en predecir la supervivencia de los pasajeros y cabin porque tiene muchos datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "Dado que hay datos categoricos con mas de dos valores posibles se deben codificar usando One hot encoder. Las columnas 'work_type', 'smoking_status' son categoricas, por lo que usamos este metodo para convertirlas en variables numericas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_type_Govt_job  work_type_Never_worked  work_type_Private  \\\n",
       "0                 0.0                     0.0                1.0   \n",
       "1                 0.0                     0.0                0.0   \n",
       "2                 0.0                     0.0                1.0   \n",
       "3                 0.0                     0.0                1.0   \n",
       "4                 0.0                     0.0                0.0   \n",
       "\n",
       "   work_type_Self-employed  work_type_children  smoking_status_Unknown  \\\n",
       "0                      0.0                 0.0                     0.0   \n",
       "1                      1.0                 0.0                     0.0   \n",
       "2                      0.0                 0.0                     0.0   \n",
       "3                      0.0                 0.0                     0.0   \n",
       "4                      1.0                 0.0                     0.0   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                             1.0                          0.0   \n",
       "1                             0.0                          1.0   \n",
       "2                             0.0                          1.0   \n",
       "3                             0.0                          0.0   \n",
       "4                             0.0                          1.0   \n",
       "\n",
       "   smoking_status_smokes  gender   age  hypertension  heart_disease  \\\n",
       "0                    0.0    Male  67.0             0              1   \n",
       "1                    0.0  Female  61.0             0              0   \n",
       "2                    0.0    Male  80.0             0              1   \n",
       "3                    1.0  Female  49.0             0              0   \n",
       "4                    0.0  Female  79.0             1              0   \n",
       "\n",
       "  ever_married Residence_type  avg_glucose_level   bmi  stroke  \n",
       "0          Yes          Urban             228.69  36.6       1  \n",
       "1          Yes          Rural             202.21   NaN       1  \n",
       "2          Yes          Rural             105.92  32.5       1  \n",
       "3          Yes          Urban             171.23  34.4       1  \n",
       "4          Yes          Rural             174.12  24.0       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = ['work_type', 'smoking_status']\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "encoded_features = encoder.fit_transform(dframe[categorical_columns])\n",
    "\n",
    "feature_names = encoder.get_feature_names_out(categorical_columns)\n",
    "\n",
    "dframe_encoded = pd.DataFrame(encoded_features, columns=feature_names)\n",
    "\n",
    "dframe = pd.concat([dframe_encoded, dframe.drop(categorical_columns, axis=1)], axis=1)\n",
    "dframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para evitar posibles problemas futuros con el entrenamiento de modelos, eliminaremos el valor \"Other\" de \"gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      work_type_Govt_job  work_type_Never_worked  work_type_Private  \\\n",
      "3116                 0.0                     0.0                1.0   \n",
      "\n",
      "      work_type_Self-employed  work_type_children  smoking_status_Unknown  \\\n",
      "3116                      0.0                 0.0                     0.0   \n",
      "\n",
      "      smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
      "3116                             1.0                          0.0   \n",
      "\n",
      "      smoking_status_smokes gender   age  hypertension  heart_disease  \\\n",
      "3116                    0.0  Other  26.0             0              0   \n",
      "\n",
      "     ever_married Residence_type  avg_glucose_level   bmi  stroke  \n",
      "3116           No          Rural             143.33  22.4       0  \n",
      "      work_type_Govt_job  work_type_Never_worked  work_type_Private  \\\n",
      "3116                 0.0                     0.0                1.0   \n",
      "\n",
      "      work_type_Self-employed  work_type_children  smoking_status_Unknown  \\\n",
      "3116                      0.0                 0.0                     0.0   \n",
      "\n",
      "      smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
      "3116                             1.0                          0.0   \n",
      "\n",
      "      smoking_status_smokes gender   age  hypertension  heart_disease  \\\n",
      "3116                    0.0  Other  26.0             0              0   \n",
      "\n",
      "     ever_married Residence_type  avg_glucose_level   bmi  stroke  \n",
      "3116           No          Rural             143.33  22.4       0  \n"
     ]
    }
   ],
   "source": [
    "print(dframe[dframe['gender'] == 'Other'])\n",
    "rows_to_delete = dframe[dframe['gender'] == 'other'].index\n",
    "dframe.drop(rows_to_delete, inplace=True)\n",
    "print(dframe[dframe['gender'] == 'Other'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformamos las variables categóricas binarias en numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_type_Govt_job  work_type_Never_worked  work_type_Private  \\\n",
       "0                 0.0                     0.0                1.0   \n",
       "1                 0.0                     0.0                0.0   \n",
       "2                 0.0                     0.0                1.0   \n",
       "3                 0.0                     0.0                1.0   \n",
       "4                 0.0                     0.0                0.0   \n",
       "\n",
       "   work_type_Self-employed  work_type_children  smoking_status_Unknown  \\\n",
       "0                      0.0                 0.0                     0.0   \n",
       "1                      1.0                 0.0                     0.0   \n",
       "2                      0.0                 0.0                     0.0   \n",
       "3                      0.0                 0.0                     0.0   \n",
       "4                      1.0                 0.0                     0.0   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                             1.0                          0.0   \n",
       "1                             0.0                          1.0   \n",
       "2                             0.0                          1.0   \n",
       "3                             0.0                          0.0   \n",
       "4                             0.0                          1.0   \n",
       "\n",
       "   smoking_status_smokes  gender   age  hypertension  heart_disease  \\\n",
       "0                    0.0     0.0  67.0             0              1   \n",
       "1                    0.0     1.0  61.0             0              0   \n",
       "2                    0.0     0.0  80.0             0              1   \n",
       "3                    1.0     1.0  49.0             0              0   \n",
       "4                    0.0     1.0  79.0             1              0   \n",
       "\n",
       "   ever_married  Residence_type  avg_glucose_level   bmi  stroke  \n",
       "0             1               1             228.69  36.6       1  \n",
       "1             1               0             202.21   NaN       1  \n",
       "2             1               0             105.92  32.5       1  \n",
       "3             1               1             171.23  34.4       1  \n",
       "4             1               0             174.12  24.0       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_mapping = {'Male': 0, 'Female': 1}\n",
    "marry_mapping = {'Yes': 1, 'No': 0}\n",
    "residence_mapping = {'Urban': 1, 'Rural': 0}\n",
    "\n",
    "\n",
    "dframe['gender'] = dframe['gender'].map(gender_mapping)\n",
    "dframe['ever_married'] = dframe['ever_married'].map(marry_mapping)\n",
    "dframe['Residence_type'] = dframe['Residence_type'].map(residence_mapping)\n",
    "dframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borramos valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work_type_Govt_job                0\n",
       "work_type_Never_worked            0\n",
       "work_type_Private                 0\n",
       "work_type_Self-employed           0\n",
       "work_type_children                0\n",
       "smoking_status_Unknown            0\n",
       "smoking_status_formerly smoked    0\n",
       "smoking_status_never smoked       0\n",
       "smoking_status_smokes             0\n",
       "gender                            0\n",
       "age                               0\n",
       "hypertension                      0\n",
       "heart_disease                     0\n",
       "ever_married                      0\n",
       "Residence_type                    0\n",
       "avg_glucose_level                 0\n",
       "bmi                               0\n",
       "stroke                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe.dropna(inplace=True)\n",
    "dframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar outliers y ver si borrar ever_married"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['age', 'bmi', 'avg_glucose_level']\n",
    "scaler = MinMaxScaler()\n",
    "dframe[numerical_features] = scaler.fit_transform(dframe[numerical_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Implementación de algoritmos de minería de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 0: División de datos en train y test\n",
    "- Dividir los datos en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dframe.drop(['stroke'], axis=1)\n",
    "y = dframe['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=42)\n",
    "X_new_train, X_val, y_new_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: MLP \n",
    "- Utilizar el algoritmo MLP (Perceptrón Multicapa) para construir un modelo de predicción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(y_new_train)\n",
    "print(classes)\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(X_train.shape[1],)) # hacemos los inputs y las capas\n",
    "dense1 = Dense(128, activation=\"relu\")\n",
    "dense2 = Dense(64, activation=\"relu\")\n",
    "dense3 = Dense(len(classes), activation=\"softmax\")\n",
    "\n",
    "# hacemos\n",
    "x = dense1(inputs)\n",
    "x = dense2(x)\n",
    "outputs = dense3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 17)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2304      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,690\n",
      "Trainable params: 10,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs) # establecemos el modelo\n",
    "\n",
    "model.summary() # hacemos el resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "######\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_new_train_encoded = to_categorical(y_new_train)\n",
    "y_val_encoded = to_categorical(y_val)\n",
    "print(y_val_encoded)\n",
    "print(\"######\")\n",
    "print(y_new_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #hacemos la compilación con el optimizer\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) #establecemos callback, para establecer la patience"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Regresion Logistica \n",
    "- Implementar Regresión Logística y GMM (Modelos de Mezcla Gaussiana) como parte de un pipeline extendido. Para construir un modelo de predicción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión Logística sin GMM\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "clf = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Evaluación del modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Entrenar los modelos (MLP)\n",
    "- Entrenar los modelos con los datos de entrenamiento y evaluar su rendimiento con los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 2s 6ms/step - loss: 0.2121 - accuracy: 0.9571 - val_loss: 0.1486 - val_accuracy: 0.9636\n",
      "Epoch 2/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9592 - val_loss: 0.1399 - val_accuracy: 0.9636\n",
      "Epoch 3/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9592 - val_loss: 0.1353 - val_accuracy: 0.9636\n",
      "Epoch 4/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9592 - val_loss: 0.1343 - val_accuracy: 0.9636\n",
      "Epoch 5/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9592 - val_loss: 0.1337 - val_accuracy: 0.9636\n",
      "Epoch 6/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9592 - val_loss: 0.1315 - val_accuracy: 0.9636\n",
      "Epoch 7/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1375 - accuracy: 0.9592 - val_loss: 0.1327 - val_accuracy: 0.9636\n",
      "Epoch 8/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9592 - val_loss: 0.1326 - val_accuracy: 0.9636\n",
      "Epoch 9/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1356 - accuracy: 0.9592 - val_loss: 0.1352 - val_accuracy: 0.9636\n",
      "Epoch 10/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9592 - val_loss: 0.1352 - val_accuracy: 0.9636\n",
      "Epoch 11/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9596 - val_loss: 0.1338 - val_accuracy: 0.9636\n",
      "Epoch 12/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9592 - val_loss: 0.1352 - val_accuracy: 0.9636\n",
      "Epoch 13/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9592 - val_loss: 0.1364 - val_accuracy: 0.9636\n",
      "Epoch 14/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9585 - val_loss: 0.1355 - val_accuracy: 0.9636\n",
      "Epoch 15/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9600 - val_loss: 0.1357 - val_accuracy: 0.9651\n",
      "Epoch 16/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9603 - val_loss: 0.1388 - val_accuracy: 0.9636\n",
      "Epoch 17/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9592 - val_loss: 0.1395 - val_accuracy: 0.9651\n",
      "Epoch 18/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9596 - val_loss: 0.1396 - val_accuracy: 0.9636\n",
      "Epoch 19/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.9592 - val_loss: 0.1383 - val_accuracy: 0.9636\n",
      "Epoch 20/20\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9614 - val_loss: 0.1460 - val_accuracy: 0.9651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22710ab4b80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_new_train, y_new_train_encoded, batch_size=32, epochs=20, validation_data=(X_val, y_val_encoded), callbacks=[callback])\n",
    "#finalmente hacemos model fit, para entrenar al modelo con los datos de entrenamiento, ademas usando la data de validación dicha antes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Metricas de evaluación (MLP)\n",
    "- Utilizar métricas de evaluación adecuadas, como precisión, sensibilidad, especificidad y F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 2ms/step\n",
      "Test Accuracy : 0.9456890699253224\n",
      "\n",
      "Classification Report : \n",
      "[0 1] [0 1] [0 1] [0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1401\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.95      1473\n",
      "   macro avg       0.48      0.50      0.49      1473\n",
      "weighted avg       0.90      0.95      0.92      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_preds = model.predict(X_test).argmax(axis=-1) #finalmente, hacemos la predicción\n",
    "\n",
    "print(\"Test Accuracy : {}\".format(accuracy_score(y_test, Y_preds)))\n",
    "print(\"\\nClassification Report : \")\n",
    "\n",
    "print(np.unique(y_test), np.unique(Y_preds), np.unique(y_new_train), np.unique(y_val)) #esta linea nos dejara algo claro que\n",
    "#veremos mas adelante\n",
    "labels = ['0', '1'] #establecemos los labels de las clases\n",
    "print(classification_report(y_test, Y_preds,zero_division=0, target_names=labels))#hacemos el casification report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Entrenar los modelos (RL)\n",
    "- Entrenar los modelos con los datos de entrenamiento y evaluar su rendimiento con los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo de regresión logística\n",
    "clf.fit(X_new_train, y_new_train)\n",
    "\n",
    "# Predicción del modelo de regresión logística\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Metricas de evaluación (RL)\n",
    "- Utilizar métricas de evaluación adecuadas, como precisión, sensibilidad, especificidad y F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.745417515274949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85      1401\n",
      "           1       0.15      0.86      0.25        72\n",
      "\n",
      "    accuracy                           0.75      1473\n",
      "   macro avg       0.57      0.80      0.55      1473\n",
      "weighted avg       0.95      0.75      0.82      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo de regresión logística\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Análisis de resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Interpretación de resultados\n",
    "- Interpretar y analizar los resultados obtenidos de los diferentes modelos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basado en los resultados, podemos ver que MLP tiene precisión del 0% para los datos 1 en \"stroke\". Por otro lado, podemos observar que RL igualmente tiene una baja precisión, aunque mejor en comparación con MLP. Esto significa que estamos experimentado problemas con la clasificación, y los modelos no están logrando aprender los patrones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un desbalance de datos notorio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Por mejorar\n",
    "- Realizar ajustes o mejoras en el modelo según sea necesario."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM (para data augmentation) o alguna otro metodo de data augmentation, basada en la forma de los datos.\n",
    "\n",
    "Priorizar algunas columnas por sobre otras (cambio de pesos).\n",
    "\n",
    "Investigar eliminación de columnas.\n",
    "\n",
    "Probar con otros modelos y/o cambiar hiperparametros de los modelos. (Activation, optimizer, epochs)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Implementación de mejoras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Manejo del desbalance de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para manejar el desbalance de datos haremos un submuestreo de la clase mayoritaria, en este caso 'stroke' = 0. Cada muestra será combinada con la misma muestra de la clase minoritara, 'stroke' = 1. Recordemos que tenemos 249 filas con 'stroke' = 1 y 4861 filas con 'stroke' = 0. Pero estos valores se vieron afectados por el preprocesamiento por lo que para saber cuantos grupos de muestras necesitamos primero hay que verificar el balance actual."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero separamos el dataframe según su etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 4699\n"
     ]
    }
   ],
   "source": [
    "stroke_1 = dframe[dframe['stroke'] == 1]\n",
    "stroke_0 = dframe[dframe['stroke'] == 0]\n",
    "\n",
    "print(stroke_1.shape[0], stroke_0.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, ahora tenemos 209 filas de etiqueta = 1 y 4699 filas = 0. Hacemos una división entera para ver cuantos grupos de 209 filas podemos hacer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4699//209"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es hacer el submuestreo tomando muestras de 249 filas de stroke_0, por lo que tomaremos 22 muestras al azar. Para evitar cualquier tipo de sesgo u orden intrínseco en que se ordenaron los datos en un inicio, reordenaremos las filas de stroke_0 de manera aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_0_shuffled = stroke_0.sample(frac=1, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos en 22 grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4699\n",
      "4699\n"
     ]
    }
   ],
   "source": [
    "stroke_0_groups = np.array_split(stroke_0_shuffled, 22)\n",
    "count = 0\n",
    "for i in range(22):\n",
    "    count +=stroke_0_groups[i].shape[0]\n",
    "\n",
    "print(count)\n",
    "print(stroke_0_shuffled.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien las muestras no son todas del mismo tamaño, terminan sumando la cantidad correcta de columnas, por lo que procedemos a concatenar cada muestra de stroke_0 con la misma muestra de stroke_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sets = []\n",
    "for group in stroke_0_groups:\n",
    "    training_set = pd.concat([stroke_1, group])\n",
    "    training_sets.append(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(training_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    214\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    213\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    213\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    213\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    213\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    213\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    213\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    213\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    213\n",
      "1    209\n",
      "Name: count, dtype: int64\n",
      "stroke\n",
      "0    213\n",
      "1    209\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for sets in training_sets:\n",
    "    print(sets['stroke'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera general podemos ver que cada grupo tiene balance de clases, por lo que ahora entrenaremos distintos modelos de Regresión Logistica en base a cada uno de estos grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7086614173228346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68        59\n",
      "           1       0.72      0.75      0.73        68\n",
      "\n",
      "    accuracy                           0.71       127\n",
      "   macro avg       0.71      0.71      0.71       127\n",
      "weighted avg       0.71      0.71      0.71       127\n",
      "\n",
      "Accuracy: 0.7086614173228346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        59\n",
      "           1       0.71      0.76      0.74        68\n",
      "\n",
      "    accuracy                           0.71       127\n",
      "   macro avg       0.71      0.70      0.71       127\n",
      "weighted avg       0.71      0.71      0.71       127\n",
      "\n",
      "Accuracy: 0.7401574803149606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73        59\n",
      "           1       0.77      0.74      0.75        68\n",
      "\n",
      "    accuracy                           0.74       127\n",
      "   macro avg       0.74      0.74      0.74       127\n",
      "weighted avg       0.74      0.74      0.74       127\n",
      "\n",
      "Accuracy: 0.8110236220472441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80        59\n",
      "           1       0.83      0.81      0.82        68\n",
      "\n",
      "    accuracy                           0.81       127\n",
      "   macro avg       0.81      0.81      0.81       127\n",
      "weighted avg       0.81      0.81      0.81       127\n",
      "\n",
      "Accuracy: 0.7874015748031497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78        59\n",
      "           1       0.83      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.79       127\n",
      "   macro avg       0.79      0.79      0.79       127\n",
      "weighted avg       0.79      0.79      0.79       127\n",
      "\n",
      "Accuracy: 0.7480314960629921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72        59\n",
      "           1       0.76      0.78      0.77        68\n",
      "\n",
      "    accuracy                           0.75       127\n",
      "   macro avg       0.75      0.75      0.75       127\n",
      "weighted avg       0.75      0.75      0.75       127\n",
      "\n",
      "Accuracy: 0.7322834645669292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72        59\n",
      "           1       0.76      0.74      0.75        68\n",
      "\n",
      "    accuracy                           0.73       127\n",
      "   macro avg       0.73      0.73      0.73       127\n",
      "weighted avg       0.73      0.73      0.73       127\n",
      "\n",
      "Accuracy: 0.7086614173228346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67        59\n",
      "           1       0.71      0.78      0.74        68\n",
      "\n",
      "    accuracy                           0.71       127\n",
      "   macro avg       0.71      0.70      0.70       127\n",
      "weighted avg       0.71      0.71      0.71       127\n",
      "\n",
      "Accuracy: 0.7322834645669292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69        59\n",
      "           1       0.72      0.81      0.76        68\n",
      "\n",
      "    accuracy                           0.73       127\n",
      "   macro avg       0.73      0.73      0.73       127\n",
      "weighted avg       0.73      0.73      0.73       127\n",
      "\n",
      "Accuracy: 0.7322834645669292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72        59\n",
      "           1       0.77      0.72      0.74        68\n",
      "\n",
      "    accuracy                           0.73       127\n",
      "   macro avg       0.73      0.73      0.73       127\n",
      "weighted avg       0.73      0.73      0.73       127\n",
      "\n",
      "Accuracy: 0.7322834645669292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73        59\n",
      "           1       0.78      0.69      0.73        68\n",
      "\n",
      "    accuracy                           0.73       127\n",
      "   macro avg       0.73      0.74      0.73       127\n",
      "weighted avg       0.74      0.73      0.73       127\n",
      "\n",
      "Accuracy: 0.7086614173228346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        59\n",
      "           1       0.71      0.76      0.74        68\n",
      "\n",
      "    accuracy                           0.71       127\n",
      "   macro avg       0.71      0.70      0.71       127\n",
      "weighted avg       0.71      0.71      0.71       127\n",
      "\n",
      "Accuracy: 0.7559055118110236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75        59\n",
      "           1       0.79      0.74      0.76        68\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.76      0.76      0.76       127\n",
      "weighted avg       0.76      0.76      0.76       127\n",
      "\n",
      "Accuracy: 0.7795275590551181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77        59\n",
      "           1       0.80      0.78      0.79        68\n",
      "\n",
      "    accuracy                           0.78       127\n",
      "   macro avg       0.78      0.78      0.78       127\n",
      "weighted avg       0.78      0.78      0.78       127\n",
      "\n",
      "Accuracy: 0.7637795275590551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        59\n",
      "           1       0.78      0.78      0.78        68\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.76      0.76      0.76       127\n",
      "weighted avg       0.76      0.76      0.76       127\n",
      "\n",
      "Accuracy: 0.7244094488188977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69        59\n",
      "           1       0.73      0.78      0.75        68\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.72      0.72      0.72       127\n",
      "weighted avg       0.72      0.72      0.72       127\n",
      "\n",
      "Accuracy: 0.7716535433070866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76        59\n",
      "           1       0.79      0.78      0.79        68\n",
      "\n",
      "    accuracy                           0.77       127\n",
      "   macro avg       0.77      0.77      0.77       127\n",
      "weighted avg       0.77      0.77      0.77       127\n",
      "\n",
      "Accuracy: 0.7637795275590551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75        59\n",
      "           1       0.80      0.75      0.77        68\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.76      0.76      0.76       127\n",
      "weighted avg       0.77      0.76      0.76       127\n",
      "\n",
      "Accuracy: 0.7716535433070866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75        59\n",
      "           1       0.78      0.79      0.79        68\n",
      "\n",
      "    accuracy                           0.77       127\n",
      "   macro avg       0.77      0.77      0.77       127\n",
      "weighted avg       0.77      0.77      0.77       127\n",
      "\n",
      "Accuracy: 0.8188976377952756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.82        59\n",
      "           1       0.87      0.78      0.82        68\n",
      "\n",
      "    accuracy                           0.82       127\n",
      "   macro avg       0.82      0.82      0.82       127\n",
      "weighted avg       0.82      0.82      0.82       127\n",
      "\n",
      "Accuracy: 0.7244094488188977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68        59\n",
      "           1       0.72      0.79      0.76        68\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.73      0.72      0.72       127\n",
      "weighted avg       0.73      0.72      0.72       127\n",
      "\n",
      "Accuracy: 0.7637795275590551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        59\n",
      "           1       0.82      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.77      0.77      0.76       127\n",
      "weighted avg       0.77      0.76      0.76       127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_models = []\n",
    "\n",
    "for training_set in training_sets:\n",
    "    X = training_set.drop('stroke', axis=1)\n",
    "    y = training_set['stroke']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=42)\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    logistic_models.append(clf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que al accuracy en general más o menos se mantuvo para cada modelo, pero la precisión para predecir los 1 subió considerablemente, por lo que ahora construiremos un modelo que use todos estos modelos y nos de un resultado final."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a definir el dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dframe.drop(['stroke'], axis=1)\n",
    "y = dframe['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos las predicciones en cada modelo, pero ahora utilizando los mismos datos en todos y almacenamos las predicciones de cada modelo para crear el ensemble."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = []\n",
    "\n",
    "for model in logistic_models:\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create a list of tuples (name, model) for the VotingClassifier\n",
    "ensemble_models = [('logistic_' + str(i), model) for i, model in enumerate(logistic_models)]\n",
    "\n",
    "# Create the VotingClassifier with majority voting\n",
    "voting_classifier = VotingClassifier(estimators=ensemble_models, voting='hard')\n",
    "voting_classifier.fit(X_train, y_train)  # Train the ensemble model\n",
    "ensemble_prediction = voting_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7637795275590551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        59\n",
      "           1       0.82      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.77      0.77      0.76       127\n",
      "weighted avg       0.77      0.76      0.76       127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, ensemble_prediction))\n",
    "print(classification_report(y_test, ensemble_prediction))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con otros modelos de ensemble"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier\n",
    "meta_classifier = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=ensemble_models,\n",
    "    final_estimator=meta_classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7007874015748031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.70        59\n",
      "           1       0.75      0.66      0.70        68\n",
      "\n",
      "    accuracy                           0.70       127\n",
      "   macro avg       0.70      0.70      0.70       127\n",
      "weighted avg       0.71      0.70      0.70       127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basandonos en los métodos ya aplicados, probaremos usando modelos de Decision Trees en lugar de Regresión Logística y los ensamblaremos en un modelo de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 4699\n"
     ]
    }
   ],
   "source": [
    "stroke_1 = dframe[dframe['stroke'] == 1]\n",
    "stroke_0 = dframe[dframe['stroke'] == 0]\n",
    "\n",
    "print(stroke_1.shape[0], stroke_0.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_0_shuffled = stroke_0.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4699\n",
      "4699\n"
     ]
    }
   ],
   "source": [
    "stroke_0_groups = np.array_split(stroke_0_shuffled, 5)\n",
    "count = 0\n",
    "for i in range(5):\n",
    "    count +=stroke_0_groups[i].shape[0]\n",
    "\n",
    "print(count)\n",
    "print(stroke_0_shuffled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sets = []\n",
    "for group in stroke_0_groups:\n",
    "    training_set = pd.concat([stroke_1, group])\n",
    "    training_sets.append(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7507246376811594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85       285\n",
      "           1       0.30      0.32      0.31        60\n",
      "\n",
      "    accuracy                           0.75       345\n",
      "   macro avg       0.58      0.58      0.58       345\n",
      "weighted avg       0.76      0.75      0.75       345\n",
      "\n",
      "Accuracy: 0.7797101449275362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       285\n",
      "           1       0.40      0.52      0.45        60\n",
      "\n",
      "    accuracy                           0.78       345\n",
      "   macro avg       0.64      0.68      0.66       345\n",
      "weighted avg       0.81      0.78      0.79       345\n",
      "\n",
      "Accuracy: 0.7536231884057971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       285\n",
      "           1       0.27      0.25      0.26        60\n",
      "\n",
      "    accuracy                           0.75       345\n",
      "   macro avg       0.56      0.55      0.56       345\n",
      "weighted avg       0.75      0.75      0.75       345\n",
      "\n",
      "Accuracy: 0.7739130434782608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86       285\n",
      "           1       0.36      0.38      0.37        60\n",
      "\n",
      "    accuracy                           0.77       345\n",
      "   macro avg       0.61      0.62      0.62       345\n",
      "weighted avg       0.78      0.77      0.78       345\n",
      "\n",
      "Accuracy: 0.744927536231884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84       284\n",
      "           1       0.31      0.36      0.33        61\n",
      "\n",
      "    accuracy                           0.74       345\n",
      "   macro avg       0.58      0.59      0.59       345\n",
      "weighted avg       0.76      0.74      0.75       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_models = []\n",
    "\n",
    "for training_set in training_sets:\n",
    "    X = training_set.drop('stroke', axis=1)\n",
    "    y = training_set['stroke']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=42)\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    decision_tree_models.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=len(decision_tree_models))\n",
    "random_forest.estimators_ = decision_tree_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dframe.drop(['stroke'], axis=1)\n",
    "y = dframe['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9470468431771895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1401\n",
      "           1       0.33      0.08      0.13        72\n",
      "\n",
      "    accuracy                           0.95      1473\n",
      "   macro avg       0.64      0.54      0.55      1473\n",
      "weighted avg       0.92      0.95      0.93      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de ensembles sin aplicar el submuestreo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dframe.drop(['stroke'], axis=1)\n",
    "y = dframe['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth = 2 and t = 50 The accuracy is : 0.9395790902919212\n",
      "For max_depth = 2 and t = 100 The accuracy is : 0.9361846571622539\n",
      "For max_depth = 2 and t = 150 The accuracy is : 0.9341479972844535\n",
      "For max_depth = 3 and t = 50 The accuracy is : 0.9314324507807196\n",
      "For max_depth = 3 and t = 100 The accuracy is : 0.9368635437881874\n",
      "For max_depth = 3 and t = 150 The accuracy is : 0.9416157501697217\n",
      "For max_depth = 4 and t = 50 The accuracy is : 0.9389002036659878\n",
      "For max_depth = 4 and t = 100 The accuracy is : 0.9402579769178547\n",
      "For max_depth = 4 and t = 150 The accuracy is : 0.9470468431771895\n",
      "For max_depth = 5 and t = 50 The accuracy is : 0.945010183299389\n",
      "For max_depth = 5 and t = 100 The accuracy is : 0.9497623896809233\n",
      "For max_depth = 5 and t = 150 The accuracy is : 0.9490835030549898\n"
     ]
    }
   ],
   "source": [
    "max_depth_values = [2, 3, 4, 5]\n",
    "range_T = [50, 100, 150]\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    for t_ in range_T:\n",
    "        clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=max_depth), n_estimators=t_, random_state=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(\n",
    "            \"For max_depth =\", \n",
    "            max_depth,\n",
    "            \"and t =\",\n",
    "            t_,\n",
    "            \"The accuracy is :\",\n",
    "            acc,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1401\n",
      "           1       0.25      0.01      0.03        72\n",
      "\n",
      "    accuracy                           0.95      1473\n",
      "   macro avg       0.60      0.51      0.50      1473\n",
      "weighted avg       0.92      0.95      0.93      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
